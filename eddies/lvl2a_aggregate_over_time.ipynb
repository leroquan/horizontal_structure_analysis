{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "108f85d9c4eb58dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = 'geneva_200m'\n",
    "params_file = 'swirl_03'\n",
    "output_folder = r'../Outputs'\n",
    "\n",
    "lvl1_filename = f'{model}_{params_file}_day1_lvl1.csv'\n",
    "output_filename = f'{model}_{params_file}_day1_lvl2a.csv'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc195934c0a8ca39",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import catalogue lvl1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd6746cad608b87"
  },
  {
   "cell_type": "code",
   "source": [
    "level1_csv_path = os.path.join(output_folder, lvl1_filename)\n",
    "level1_data = pd.read_csv(level1_csv_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1839e31700b02673",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create catalogue lvl2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "846045d287a4ee21"
  },
  {
   "cell_type": "code",
   "source": [
    "def ranges_intersect(min1, max1, min2, max2):\n",
    "    return max1 >= min2 and max2 >= min1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c459ffdfefd1539",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_center_distance(df1, df2):\n",
    "    return np.sqrt((df1['xc_mean'] - df2['xc_mean'])**2 + (df1['yc_mean'] - df2['yc_mean'])**2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ee062145a772b8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to identify the different depths of an eddy\n",
    "def track_eddy(level1_data, id_eddy, idx_already_aggregated, dist_threshold, time_threshold):\n",
    "    mask = (\n",
    "        (~level1_data['id'].isin(idx_already_aggregated)) &\n",
    "        level1_data.apply(lambda row: ranges_intersect(row['depth_min_[m]'],row['depth_max_[m]'],level1_data.at[id_eddy, 'depth_min_[m]'],level1_data.at[id_eddy, 'depth_max_[m]']), axis=1) &\n",
    "        (level1_data['rotation_direction'] == level1_data.at[id_eddy, 'rotation_direction']) &\n",
    "        (compute_center_distance(level1_data, level1_data.iloc[id_eddy]) < dist_threshold * 3) # First a rough distance threshold\n",
    "    )\n",
    "    \n",
    "    filtered_eddies = level1_data.loc[mask]\n",
    "    filtered_eddies = filtered_eddies.copy()\n",
    "    filtered_eddies['parsed_date'] = pd.to_datetime(filtered_eddies['date'])\n",
    "    \n",
    "    sorted_by_date = filtered_eddies.sort_values('parsed_date', ascending=True).reset_index(drop=False)\n",
    "    \n",
    "    aggregated_eddy = sorted_by_date.iloc[[0]]\n",
    "    for i in range(1,len(sorted_by_date)):\n",
    "        distance_criteria = compute_center_distance(sorted_by_date.iloc[i], aggregated_eddy.iloc[-1]) < dist_threshold # and now the refined distance threshold\n",
    "        time_criteria = sorted_by_date.iloc[i]['time_index'] - sorted_by_date.iloc[i-1]['time_index'] <= time_threshold\n",
    "        \n",
    "        if ~time_criteria:     \n",
    "            break\n",
    "            \n",
    "        if distance_criteria:\n",
    "            aggregated_eddy = pd.concat([aggregated_eddy, sorted_by_date.iloc[[i]]], ignore_index=True)\n",
    "    \n",
    "    return aggregated_eddy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a5f0fa84f2455a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "dist_threshold = 5 # in number of cells\n",
    "time_threshold = 2 # in number of timestep\n",
    "timestep_in_seconds = 3600\n",
    "\n",
    "# Main loop\n",
    "eddy_rows_lvl2a= []  # Collect aggregated rows here\n",
    "id_level2a = 0\n",
    "idx_already_aggregated = set()\n",
    "for idx in level1_data['id']: \n",
    "    if idx in idx_already_aggregated:\n",
    "        continue\n",
    "        \n",
    "    aggregated_data = track_eddy(level1_data, idx, idx_already_aggregated, dist_threshold, time_threshold)\n",
    "    lifespan = (timestep_in_seconds + (pd.to_datetime(aggregated_data['date'].iloc[-1]) - pd.to_datetime(aggregated_data['date'].iloc[0])).total_seconds()) / 3600\n",
    "\n",
    "    row = {\n",
    "        'id': id_level2a,\n",
    "        'id_lvl1': aggregated_data['id'].tolist(),\n",
    "        'time_indices(t)': aggregated_data['time_index'].tolist(),\n",
    "        'dates(t)': aggregated_data['date'].tolist(),\n",
    "        'xc(t)': aggregated_data['xc_mean'].tolist(),\n",
    "        'yc(t)': aggregated_data['yc_mean'].tolist(),\n",
    "        'depth_min(t)_[m]': aggregated_data['depth_min_[m]'].tolist(),\n",
    "        'depth_max(t)_[m]': aggregated_data['depth_max_[m]'].tolist(),\n",
    "        'volume(t)_[m3]': aggregated_data['volume_[m3]'].tolist(),\n",
    "        'rotation_direction': aggregated_data.at[0, 'rotation_direction'],\n",
    "        'kinetic_energy(t)_[MJ]': aggregated_data['kinetic_energy_[MJ]'].tolist(),\n",
    "        'lifespan_[h]': lifespan\n",
    "    }\n",
    "\n",
    "    eddy_rows_lvl2a.append(row)\n",
    "    idx_already_aggregated.update(aggregated_data['id'].tolist())\n",
    "    id_level2a += 1\n",
    "\n",
    "# Create the final DataFrame using pd.concat\n",
    "df_catalogue_level2 = pd.concat([pd.DataFrame([row]) for row in eddy_rows_lvl2a], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b140be02be95d42",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_catalogue_level2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7bce6d5cdbc2358",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a947baf764c4dd"
  },
  {
   "cell_type": "code",
   "source": [
    "df_catalogue_level2.to_csv(os.path.join(output_folder, output_filename), index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9b1df834796a039",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "21516cc8946e70f8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
